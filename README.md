# TraceBridge AI

**AI-Powered FDA 510(k) Regulatory Compliance Analysis Platform**

TraceBridge AI uses Retrieval-Augmented Generation (RAG) to analyze medical device submissions against FDA requirements, automatically detecting documentation gaps and predicting Refusal to Accept (RTA) risk.

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FRONTEND (React + Vite)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Landing  â”‚â†’ â”‚  Upload  â”‚â†’ â”‚ Analysis â”‚â†’ â”‚ Results  â”‚â†’ â”‚ Remediation  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ HTTP/REST
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           BACKEND (FastAPI + Python)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         API LAYER (Routers)                          â”‚    â”‚
â”‚  â”‚  POST /upload    POST /query    POST /gap-report    GET /documents   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        SERVICE LAYER                                 â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  Parser  â”‚  â”‚  Chunker  â”‚  â”‚   Indexer   â”‚  â”‚  LLM Service   â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ PDF/DOCX â”‚  â”‚ 500 chars â”‚  â”‚ Embeddings  â”‚  â”‚ GPT-4 + Guard  â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚                    Gap Analysis Service                       â”‚  â”‚    â”‚
â”‚  â”‚  â”‚    FDA Requirements Matching + Severity Classification        â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                           â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   ChromaDB   â”‚            â”‚   OpenAI     â”‚
           â”‚ Vector Store â”‚            â”‚   GPT-4 API  â”‚
           â”‚ (Embeddings) â”‚            â”‚  (text-gen)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
TraceBridge/
â”œâ”€â”€ app/                        # Backend API
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry
â”‚   â”œâ”€â”€ config.py               # Environment settings
â”‚   â”œâ”€â”€ models.py               # Pydantic schemas
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ documents.py        # /upload, /documents endpoints
â”‚   â”‚   â””â”€â”€ query.py            # /query, /gap-report endpoints
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ parser.py           # PDF/DOCX parsing
â”‚       â”œâ”€â”€ chunker.py          # Text chunking with overlap
â”‚       â”œâ”€â”€ indexer.py          # ChromaDB vector indexing
â”‚       â”œâ”€â”€ llm.py              # OpenAI integration + verification
â”‚       â””â”€â”€ gap_analysis.py     # FDA requirement matching
â”‚
â”œâ”€â”€ frontend/                   # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Router setup
â”‚   â”‚   â”œâ”€â”€ index.css           # Design system
â”‚   â”‚   â”œâ”€â”€ api/client.js       # Backend API client
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StepIndicator.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ GapDetailModal.jsx
â”‚   â”‚   â”‚   â””â”€â”€ RemediationPlanModal.jsx
â”‚   â”‚   â””â”€â”€ pages/
â”‚   â”‚       â”œâ”€â”€ Landing.jsx
â”‚   â”‚       â”œâ”€â”€ Upload.jsx
â”‚   â”‚       â”œâ”€â”€ Analysis.jsx
â”‚   â”‚       â”œâ”€â”€ Results.jsx
â”‚   â”‚       â””â”€â”€ Documentation.jsx
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ uploads/                    # Stored uploaded files
â”œâ”€â”€ chroma_data/               # Vector database storage
â”œâ”€â”€ .env                       # Environment variables
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ docker-compose.yml         # Container deployment
```

---

## ğŸ”„ Data Flow

### 1. Document Upload Flow
```
User uploads PDF/DOCX
        â†“
[Parser] Extract text from document
        â†“
[Chunker] Split into 500-char chunks (100 overlap)
        â†“
[Indexer] Generate embeddings via OpenAI
        â†“
[ChromaDB] Store vectors with metadata
        â†“
Return: doc_id, chunks_indexed, standards_detected
```

### 2. RAG Query Flow
```
User query: "What V&V activities are documented?"
        â†“
[Indexer] Semantic search in ChromaDB
        â†“
Retrieve top-k relevant chunks
        â†“
[LLM Service] Build grounded prompt with context
        â†“
[GPT-4] Generate answer citing sources
        â†“
[Verification] Check for hallucination
        â†“
Return: answer, citations[], fallback_used, verification
```

### 3. Gap Analysis Flow
```
Request: device_name="CardioSense", focus_area="V&V"
        â†“
[Gap Service] Load FDA requirements for focus area
        â†“
[Indexer] Search user docs for each requirement
        â†“
[LLM] Compare and identify gaps
        â†“
Classify severity: critical | high | medium | low
        â†“
Generate remediation steps
        â†“
Return: gaps[], total_gaps, severity_breakdown
```

---

## ğŸ§  RAG Implementation Details

### Embedding Strategy
- **Model**: OpenAI `text-embedding-3-small`
- **Dimension**: 1536
- **Fallback**: Sentence Transformers (offline)

### Chunking Strategy
```python
chunk_size = 500      # Characters per chunk
chunk_overlap = 100   # Overlap between chunks
```

### Retrieval Parameters
```python
top_k = 5             # Default chunks to retrieve
similarity_threshold = 0.7  # Minimum relevance
```

### Hallucination Mitigation
1. **Grounded Prompts**: LLM instructed to cite only provided context
2. **Verification Layer**: Post-generation confidence check
3. **Fallback Handling**: Falls back to retrieval-only if verification fails
4. **Citation Tracking**: Every claim must reference source chunk

---

## ğŸ›¡ï¸ Regulatory Standards Supported

| Standard | Description |
|----------|-------------|
| ISO 10993 | Biocompatibility Testing |
| IEC 62304 | Medical Device Software |
| ISO 14971 | Risk Management |
| ISO 13485 | Quality Management |
| IEC 60601 | Electrical Safety |
| 21 CFR Part 820 | FDA Quality System |

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- OpenAI API Key

### Backend Setup
```bash
cd TraceBridge
python -m venv venv
.\venv\Scripts\activate        # Windows
source venv/bin/activate       # Linux/Mac
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# Start server
uvicorn app.main:app --reload --port 8000
```

### Frontend Setup
```bash
cd frontend
npm install
npm run dev
```

### Access
- **Frontend**: http://localhost:5173
- **API Docs**: http://localhost:8000/docs

---

## ğŸ“¡ API Reference

### POST /upload
Upload and index a document.

**Request:**
```bash
curl -X POST http://localhost:8000/upload \
  -F "file=@document.pdf" \
  -F "device_name=CardioSense Pro" \
  -F "doc_type=vnv"
```

**Response:**
```json
{
  "doc_id": "abc123",
  "filename": "document.pdf",
  "chunks_indexed": 45,
  "standards_detected": ["IEC 62304", "ISO 14971"]
}
```

### POST /query
RAG query with citations.

**Request:**
```json
{
  "query": "What verification tests were performed?",
  "device_name": "CardioSense Pro",
  "top_k": 5
}
```

**Response:**
```json
{
  "success": true,
  "answer": "The submission includes...",
  "citations": [
    {
      "chunk_id": "chunk_12",
      "snippet": "...",
      "relevance_score": 0.89,
      "page_number": 5
    }
  ],
  "fallback_used": false
}
```

### POST /gap-report
Generate gap analysis report.

**Request:**
```json
{
  "device_name": "CardioSense Pro",
  "focus_area": "V&V"
}
```

**Response:**
```json
{
  "success": true,
  "device_name": "CardioSense Pro",
  "gaps": [
    {
      "category": "V&V",
      "severity": "critical",
      "fda_requirement": "Software unit testing",
      "evidence_found": null,
      "gap_description": "No unit test documentation",
      "remediation_steps": ["Add unit test reports"]
    }
  ],
  "total_gaps": 3
}
```

---

## ğŸ¨ Frontend Architecture

### Component Hierarchy
```
App
â”œâ”€â”€ Header (navigation)
â”œâ”€â”€ Routes
â”‚   â”œâ”€â”€ Landing (hero + features)
â”‚   â”œâ”€â”€ Upload (form + file upload)
â”‚   â”œâ”€â”€ Analysis (progress + API calls)
â”‚   â”œâ”€â”€ Results (gaps + actions)
â”‚   â””â”€â”€ Documentation (API docs)
â””â”€â”€ Modals
    â”œâ”€â”€ GapDetailModal (3-column analysis)
    â””â”€â”€ RemediationPlanModal (saved items)
```

### State Management
- **Component State**: React useState for UI
- **Session Storage**: Persists workflow data between pages
  - `analysisData`: Device info, doc IDs, standards
  - `gapReport`: Gap analysis results
  - `queryResult`: RAG query response
  - `remediationPlan`: Saved gap items
  - `acknowledgedGaps`: User acknowledgments

### Design System
- **Colors**: Primary blue (#1a4b8c), gradient to teal (#00b894)
- **Typography**: Inter font family
- **Effects**: Glassmorphism, smooth animations
- **Responsive**: Mobile-first with breakpoints

---

## ğŸ”’ Security Considerations

1. **API Key Protection**: Never expose OpenAI key to frontend
2. **File Validation**: Check file types and sizes
3. **Input Sanitization**: Validate all user inputs
4. **CORS**: Configured for development origins

---

## ğŸ“Š Performance Optimizations

1. **Chunking**: Balanced size for retrieval accuracy
2. **Vector Indexing**: Persistent ChromaDB storage
3. **Lazy Loading**: Frontend components loaded on demand
4. **Session Storage**: Avoid redundant API calls

---

## ğŸ§ª Testing

### Backend
```bash
pytest tests/ -v
```

### API Health Check
```bash
curl http://localhost:8000/health
```

---

## ğŸ“ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required |
| `LLM_MODEL` | GPT model name | gpt-4o-mini |
| `CHROMA_PERSIST_DIR` | Vector DB path | ./chroma_data |
| `UPLOAD_DIR` | File storage path | ./uploads |
| `CHUNK_SIZE` | Characters per chunk | 500 |
| `CHUNK_OVERLAP` | Overlap size | 100 |

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

---

## ğŸ“„ License

MIT License - See LICENSE file for details.

---

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 and embeddings
- ChromaDB for vector storage
- FastAPI for the backend framework
- React + Vite for the frontend

---

**Built with â¤ï¸ for regulatory compliance professionals**
